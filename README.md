# Talk_to_PDF  

COming soon ...  

Special Thanks to [@Qwen3](https://github.com/QwenLM/Qwen3) and [@gemma](https://github.com/google-deepmind/gemma) teams for building efficient and high-quality low-resource usage models. 

This version uses #HuggingFace and #Ollama for local OFFLINE hardware usage. 
Min. Local Hardware Req. => RAM: 32GB, GPU: 6-8GB (NVIDIA) 

